{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"C:\\Users\\91915\\Desktop\\Prodigy @ T-1\\Datasets//train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_var = df_train.select_dtypes(include = [\"object\"]).columns\n",
    "num_var = df_train.select_dtypes(exclude = [\"object\"]).columns\n",
    "num_var = num_var.drop(\"SalePrice\")\n",
    "print(\"Numerical variables : \" + str(len(num_var)))\n",
    "print(\"Categorical variables : \" + str(len(cat_var)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SalePrice'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_train['SalePrice'], kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % df_train['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing =df_train.isnull().sum().sort_values(ascending=False)\n",
    "total = df_train.isnull().count().sort_values(ascending=False)\n",
    "NotNull =(total - missing).sort_values(ascending=True)\n",
    "percent = ((df_train.isnull().sum()/df_train.isnull().count())*100).sort_values(ascending=False)\n",
    "missing_data = pd.concat([NotNull, missing, total, percent], axis=1, keys=['NotNull ', 'Missing', 'total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=missing_data.head(7)\n",
    "col = df0.index\n",
    "df1 = df_train.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = df1.select_dtypes(exclude=np.number).columns\n",
    "num_var = df1.select_dtypes(include=np.number).columns\n",
    "\n",
    "df_num=df_train[num_var]\n",
    "df_cat=df_train[cat_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num.drop(['Id'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical variables\n",
    "f = pd.melt(df_num)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False)\n",
    "g = g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick variables by degree of correlation\n",
    "corr = df_num.corr()\n",
    "corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "print(corr.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrS= df_num.corr(method='spearman')\n",
    "corrS.sort_values(['SalePrice'], ascending=False, inplace=True)\n",
    "corrS.SalePrice.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.melt(df_num, id_vars=['SalePrice'], value_vars=df_num.columns)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False)\n",
    "g = g.map(sns.scatterplot, \"value\",  \"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "df_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with median \n",
    "\n",
    "df_num['GarageYrBlt']=df_num['GarageYrBlt'].fillna(df_num['GarageYrBlt'].median())\n",
    "df_num['MasVnrArea']=df_num['MasVnrArea'].fillna(df_num['MasVnrArea'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7, 2, figsize=(9, 16))\n",
    "fig.suptitle('Boxplots for outlier detection')\n",
    "sns.boxplot(ax=axes[0,0], x=df_num['SalePrice'])\n",
    "sns.boxplot(ax=axes[0,1], x=df_num['OverallQual'])\n",
    "sns.boxplot(ax=axes[1,0], x=df_num['GrLivArea'])\n",
    "sns.boxplot(ax=axes[1,1], x=df_num['GarageCars'])\n",
    "sns.boxplot(ax=axes[2,0], x=df_num['GarageArea'])\n",
    "sns.boxplot(ax=axes[2,1], x=df_num['TotalBsmtSF'])\n",
    "sns.boxplot(ax=axes[3,0], x=df_num['1stFlrSF'])\n",
    "sns.boxplot(ax=axes[3,1], x=df_num['FullBath'])\n",
    "sns.boxplot(ax=axes[4,0], x=df_num['TotRmsAbvGrd'])\n",
    "sns.boxplot(ax=axes[4,1], x=df_num['YearBuilt'])\n",
    "sns.boxplot(ax=axes[5,0], x=df_num['YearRemodAdd'])\n",
    "sns.boxplot(ax=axes[5,1], x=df_num['GarageYrBlt'])\n",
    "sns.boxplot(ax=axes[6,0], x=df_num['Fireplaces'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_imputer(column_list, iqr_factor):\n",
    "    \n",
    "    for col in column_list:\n",
    "        # Reassign minimum to zero\n",
    "        df_num.loc[df_num[col] < 0, col] = 0\n",
    "\n",
    "        # Calculate upper threshold\n",
    "        q1 = df_num[col].quantile(0.25)\n",
    "        q3 = df_num[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_threshold = q3 + (iqr_factor * iqr)\n",
    "        print(col)\n",
    "        print('q3:', q3)\n",
    "        print('upper_threshold:', upper_threshold)\n",
    "\n",
    "        # Reassign values > threshold to threshold\n",
    "        df_num.loc[df_num[col] > upper_threshold, col] = upper_threshold\n",
    "        print(df_num[col].describe())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_imputer(['SalePrice'], 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.skew(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = df_num.skew(axis=0)\n",
    "skewness = skewness[abs(skewness) > 0.5 ]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "df_num[skewed_features] = np.log1p(df_num[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.concat([df_cat, df_num['SalePrice']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "f = pd.melt(df_cat, id_vars=['SalePrice'], value_vars=df_cat)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False)\n",
    "g = g.map(boxplot, \"value\", \"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "def ANOVA_Test(df, feature):\n",
    "    category_groups = df.groupby(feature)['SalePrice'].apply(list)\n",
    "    return f_oneway(*category_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = {}\n",
    "for col in df_cat.columns:\n",
    "    p_vals[col] = ANOVA_Test(df_cat, col).statistic\n",
    "p_vals.pop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(p_vals, key=p_vals.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat=df_cat.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge1=corrS.SalePrice.head(20).index\n",
    "\n",
    "purge2=sorted(p_vals, key=p_vals.get, reverse=True)[:10]\n",
    "\n",
    "df2_cat= df_cat[purge2]\n",
    "df2_num= df_num[purge1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df2_cat, df2_num], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['SalePrice']\n",
    "\n",
    "X = df2.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss=Lasso()\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=0)\n",
    "\n",
    "parameters = {'alpha': (0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(lss, parameters, n_jobs=-1, scoring='r2', cv=cv)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = grid_search.best_estimator_.predict(X_train)\n",
    "print('r2: %.3f' % grid_search.best_score_)\n",
    "print('MSE:', mean_squared_error(y_train, y_pred_train))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "print('Config: %s' % grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try on test subset\n",
    "r_sq_test = grid_search.best_estimator_.score(X_test, y_test)\n",
    "print('Coefficient of determination:', r_sq_test)\n",
    "y_pred_test = grid_search.best_estimator_.predict(X_test)\n",
    "print('R^2:', r2_score(y_test, y_pred_test))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred_test))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table =({'model': 'Lr Reg',\n",
    "                          'R2':0.84,\n",
    "                          'RMSE': 0.16\n",
    "                          },\n",
    "                         )\n",
    "\n",
    "champion =pd.DataFrame(table)\n",
    "champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly=  poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = RepeatedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "grid_search = GridSearchCV(lss, parameters, n_jobs=-1, scoring='r2', cv=cv1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = grid_search.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2: %.3f' % grid_search.best_score_)\n",
    "print('MSE:', mean_squared_error(y_train, y_pred_train))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "print('Config: %s' % grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq_test = grid_search.best_estimator_.score(X_test, y_test)\n",
    "print('Coefficient of determination:', r_sq_test)\n",
    "y_pred_test = grid_search.best_estimator_.predict(X_test)\n",
    "print('R^2:', r2_score(y_test, y_pred_test))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred_test))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_table =({'model': 'Pl Reg',\n",
    "                          'R2':0.86,\n",
    "                          'RMSE': 0.14\n",
    "                          },\n",
    "                         )\n",
    "poly_result = pd.DataFrame(poly_table)\n",
    "\n",
    "champion =  pd.concat([champion, poly_result], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "df_train=pd.read_csv(\"C:\\Users\\91915\\Desktop\\Tasks\\PRODIGY_ML_01\\PRODIGY_ML_01\\Datasets//train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoolQC : data description says NA means no pool\n",
    "df_train.loc[:, \"PoolQC\"] = df_train.loc[:, \"PoolQC\"].fillna(\"None\")\n",
    "# MiscFeature : NA most likely means no noteworthy feature\n",
    "df_train.loc[:, \"MiscFeature\"] = df_train.loc[:, \"MiscFeature\"].fillna(\"None\")\n",
    "# Alley : NA most likely means no Alley\n",
    "df_train.loc[:, \"Alley\"] = df_train.loc[:, \"Alley\"].fillna(\"None\")\n",
    "# No fence\n",
    "df_train.loc[:, \"Fence\"] = df_train.loc[:, \"Fence\"].fillna(\"None\")\n",
    "# No veneer on masonry\n",
    "df_train.loc[:, \"MasVnrType\"] = df_train.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "# No fire place\n",
    "df_train.loc[:, \"FireplaceQu\"] = df_train.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "# No frontage ft or m\n",
    "df_train.loc[:, \"LotFrontage\"] = df_train.loc[:, \"LotFrontage\"].fillna(0)\n",
    "# GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "df_train.loc[:, \"GarageType\"] = df_train.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "df_train.loc[:, \"GarageFinish\"] = df_train.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "df_train.loc[:, \"GarageQual\"] = df_train.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "df_train.loc[:, \"GarageCond\"] = df_train.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "df_train.loc[:, \"GarageArea\"] = df_train.loc[:, \"GarageArea\"].fillna(0)\n",
    "df_train.loc[:, \"GarageCars\"] = df_train.loc[:, \"GarageCars\"].fillna(0)\n",
    "df_train.loc[:, \"GarageYrBlt\"] = df_train.loc[:, \"GarageYrBlt\"].fillna(0)\n",
    "\n",
    "# BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "df_train.loc[:, \"BsmtQual\"] = df_train.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "df_train.loc[:, \"BsmtCond\"] = df_train.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "df_train.loc[:, \"BsmtExposure\"] = df_train.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "df_train.loc[:, \"BsmtFinType1\"] = df_train.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "df_train.loc[:, \"BsmtFinType2\"] = df_train.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "# No veneer area\n",
    "df_train.loc[:, \"MasVnrArea\"] = df_train.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "#misc feature value\n",
    "df_train.loc[:, \"MiscVal\"] = df_train.loc[:, \"MiscVal\"].fillna(0)\n",
    "\n",
    "\n",
    "# for electrical, there is no way to tell if it means that \n",
    "#there are no electrical works in the building, but the \n",
    "#utilities means that it possesses allpub, we will make it the mode later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PoolQC_B'] = np.where(df_train['PoolQC']=='None', 0, 1)\n",
    "\n",
    "df_train['MiscFeature_B'] = np.where(df_train['MiscFeature']=='None', 0, 1)\n",
    "\n",
    "df_train['Alley_B'] = np.where(df_train['Alley']=='None', 0, 1)\n",
    "\n",
    "df_train['Fence_B'] = np.where(df_train['Fence']=='None', 0, 1)\n",
    "\n",
    "df_train['MasVnrType_B'] = np.where(df_train['MasVnrType']=='None', 0, 1)\n",
    "\n",
    "df_train['GarageQual_B'] = np.where(df_train['MasVnrType']=='No', 0, 1)\n",
    "\n",
    "df_train['BsmtQual_B'] = np.where(df_train['MasVnrType']=='No', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.replace({\"MSZoning\" : {\"FV\" : 4, \"RL\" : 3, 'RH': 2, 'RM':2, 'C(all)':1},\n",
    "                       \"LotConfig\" : {\"CulDSac\" : 1, \"FR3\" : 1, \"FR2\" : 2, \"Corner\" : 2, \"Inside\" : 2},\n",
    "                       \"Neighborhood\" : {\"NridgHt\" : 3, \"NoRidge\" : 3, \"StoneBr\": 3, \"Timber\" : 2,  \"Somerst\" : 2, \"Veenker\": 2, \"Crawfor\" : 2, \"ClearCr\" : 2, \"CollgCr\": 2, \n",
    "                                         \"Blmngtn\" : 2, \"NWAmes\" : 2, \"Gilbert\": 2, \"SawyerW\" : 2, \"Mitchel\" : 1, \"NPkVill\": 1, \n",
    "                                         \"NAmes\" : 1, \"SWISU\" : 1, \"Blueste\": 1, \"Sawyer\" : 1, \"BrkSide\" : 1, \"Edwards\": 1, \"OldTown\" : 1,\n",
    "                                         \"BrDale\" : 1, \"IDOTRR\": 1, \"MeadowV\" : 1},\n",
    "                       \"Condition2\" : {\"PosA\" : 3, \"PosN\" : 3, \"RRAe\": 2, \"Norm\" : 2, \"RRAn\" : 1, \n",
    "                                         \"Feedr\" : 1, \"Artery\" : 1, \"RRNn\" : 1},\n",
    "                       \"BsmtFinType2\" : {\"Unf\" : 2, \"LwQ\": 2, \"Rec\" : 1, \"BLQ\" : 1, \n",
    "                                         \"ALQ\" : 2, \"GLQ\" : 3},\n",
    "                       \"BldgType\" : {\"TwnhsE\" : 2, \"1Fam\" : 2, \"Twnhs\" : 1, \"Duplex\": 1, \"2fmCon\" : 1},\n",
    "                       \"Foundation\" : {\"PConc\" : 3, \"Wood\" : 2, \"CBlock\": 2, \"Stone\": 2, \"BrkTil\": 2, \"Slab\" : 1},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 2, \"Gd\": 2, \"Ex\" : 3},\n",
    "                       \"SaleType\" : {\"Con\" : 0, \"New\" : 1, \"CWD\" : 2, \"WD\": 3, \"ConLw\" : 4, \"ConLD\" : 5 ,\n",
    "                                     \"ConLI\": 3, \"COD\" : 4, \"Oth\" : 5},\n",
    "                       \"SaleCondition\" : {\"Partial\" : 1, \"Normal\" : 2, \"Alloca\": 3, \"Family\": 4, \"Abnorml\" : 5 , \"AdjLand\" : 5},\n",
    "                       \"CentralAir\" : {\"Y\" : 2, \"N\" : 1},\n",
    "                       \"FireplaceQu\" : {\"No\" : 1,\"Po\" : 1, \"Fa\" : 1, \"TA\" : 1, \"Gd\" : 1, \"Ex\" : 2},\n",
    "                       \"MasVnrType\" : {\"Stone\" : 3, \"BrkFace\" : 2, \"BrkCmn\" : 1, \"None\" : 1},\n",
    "                       \"MiscFeature\" : {\"TenC\" : 3, \"Gar2\" : 2, \"None\" : 2, \"Shed\" : 2, \"Othr\": 1},\n",
    "                       \"Electrical\" : {\"SBrkr\" : 1, \"FuseA\" : 2, \"FuseF\" : 3, \"FuseP\" : 4, \"Mixed\": 5}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.replace({\"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"OverallScore\"] = df_train[\"OverallQual\"] * df_train[\"OverallCond\"]\n",
    "\n",
    "df_train[\"ExterScore\"] = df_train[\"ExterQual\"] * df_train[\"ExterCond\"]\n",
    "\n",
    "df_train[\"BsmtScore\"] = df_train[\"BsmtQual\"] * df_train[\"BsmtCond\"]\n",
    "\n",
    "df_train[\"FlrSF\"] = df_train[\"1stFlrSF\"] + df_train[\"2ndFlrSF\"]\n",
    "\n",
    "df_train[\"GarageScore\"] = df_train[\"GarageQual\"] * df_train[\"GarageCond\"]\n",
    "\n",
    "df_train[\"LivSF\"] = df_train[\"GrLivArea\"] + df_train[\"TotalBsmtSF\"]\n",
    "\n",
    "df_train[\"Exteroverall\"] = df_train[\"ExterQual\"] * df_train[\"OverallCond\"]\n",
    "\n",
    "df_train[\"AddedScore\"] = df_train[\"BsmtQual\"] * df_train[\"GarageQual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning continuous variables into buckets based on quantiles\n",
    "df_train['AgeBldg'] = pd.qcut(df_train['YearBuilt'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Ancient', 'Vintage', 'Old', 'Average', 'New'])\n",
    "\n",
    "df_train['LastRemod']= 2010 - df_train['YearRemodAdd']\n",
    "\n",
    "df_train['StateRemod'] = pd.qcut(df_train['LastRemod'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Critical', 'Due', 'Partial', 'Optimal', 'Newly Remod'])\n",
    "\n",
    "df_train['LotFrontageRn'] = pd.qcut(df_train['LotFrontage'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Little', 'Fair', 'Adequate', 'Good', 'Excellent'])\n",
    "\n",
    "df_train['LotAreaRn'] = pd.qcut(df_train['LotArea'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Little', 'Fair', 'Adequate', 'Good', 'Excellent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['MasVnrCov']= pd.cut(df_train['MasVnrArea'], bins=[-1, 400, 800, 1200, 1601], \n",
    "                             labels=['Small', 'Sizeable', 'Optimal', 'Excellent'])\n",
    "\n",
    "df_train['MiscValRn'] = pd.cut(df_train['MiscVal'], bins=[-1, 100, 1000, 5000, 15501], \n",
    "                             labels=['Not Valuable', 'Fair', 'Good', 'Great'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = df_train.select_dtypes(exclude=np.number).columns\n",
    "num_var = df_train.select_dtypes(include=np.number).columns\n",
    "\n",
    "df_num=df_train[num_var]\n",
    "df_cat=df_train[cat_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_imputer(['SalePrice'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrS2= df_num.corr(method='spearman')\n",
    "corrS2.sort_values(['SalePrice'], ascending=False, inplace=True)\n",
    "corrS2.SalePrice.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrS= df_num.corr(method='pearson')\n",
    "corrS.sort_values(['SalePrice'], ascending=False, inplace=True)\n",
    "corrS.SalePrice.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.concat([df_cat, df_num['SalePrice']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "def ANOVA_Test(df, feature):\n",
    "    category_groups = df.groupby(feature)['SalePrice'].apply(list)\n",
    "    return f_oneway(*category_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = {}\n",
    "for col in df_cat.columns:\n",
    "    p_vals[col] = ANOVA_Test(df_cat, col).statistic\n",
    "p_vals.pop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(p_vals, key=p_vals.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge1=corrS2.SalePrice.head(7).index\n",
    "\n",
    "purge2=sorted(p_vals, key=p_vals.get, reverse=True)[:6]\n",
    "\n",
    "df2_cat= df_cat[purge2]\n",
    "df2_num= df_num[purge1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = df2_num.skew(axis=0)\n",
    "skewness = skewness[abs(skewness) > 0.5 ]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "df2_num[skewed_features] = np.log1p(df2_num[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df2_cat, df2_num], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.get_dummies(df1, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['SalePrice']\n",
    "\n",
    "X = df1.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss=Lasso()\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=0)\n",
    "\n",
    "parameters = {'alpha': (0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(lss, parameters, n_jobs=-1, scoring='r2', cv=cv)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = grid_search.best_estimator_.predict(X_train)\n",
    "print('r2: %.3f' % grid_search.best_score_)\n",
    "print('MSE:', mean_squared_error(y_train, y_pred_train))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "print('Config: %s' % grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq_test = grid_search.best_estimator_.score(X_test, y_test)\n",
    "print('Coefficient of determination:', r_sq_test)\n",
    "y_pred_test = grid_search.best_estimator_.predict(X_test)\n",
    "print('R^2:', r2_score(y_test, y_pred_test))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred_test))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly=  poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = RepeatedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "grid_search = GridSearchCV(lss, parameters, n_jobs=-1, scoring='r2', cv=cv1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = grid_search.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r2: %.3f' % grid_search.best_score_)\n",
    "print('MSE:', mean_squared_error(y_train, y_pred_train))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "print('Config: %s' % grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq_test = grid_search.best_estimator_.score(X_test, y_test)\n",
    "print('Coefficient of determination:', r_sq_test)\n",
    "y_pred_test = grid_search.best_estimator_.predict(X_test)\n",
    "print('R^2:', r2_score(y_test, y_pred_test))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred_test))\n",
    "print('RMSE:',np.sqrt(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 =({'model': 'FE_LR Reg',\n",
    "                          'R2':0.83,\n",
    "                          'RMSE': 0.16\n",
    "                          },\n",
    "             {'model': 'FE_Poly Reg',\n",
    "                          'R2':0.83,\n",
    "                          'RMSE': 0.16\n",
    "                          },\n",
    "                         )\n",
    "result22 = pd.DataFrame(table2)\n",
    "\n",
    "champion =  pd.concat([champion, result22], axis=0)\n",
    "champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data={'actual': (np.expm1(y_test)),\n",
    "                             'predicted': (np.expm1(y_pred_test.ravel()))})\n",
    "results['residual'] = results['actual'] - results['predicted']\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.set(style='whitegrid')\n",
    "sns.scatterplot(x='actual',\n",
    "                y='predicted',\n",
    "                data=results,\n",
    "                s=20,\n",
    "                alpha=0.5,\n",
    "                ax=ax\n",
    ")\n",
    "plt.plot([0,600000], [0,600000], c='red', linewidth=2)\n",
    "plt.title('Actual vs. predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(results['residual']) #bins=np.arange(-15,15.5,0.5))\n",
    "plt.title('Distribution of the residuals')\n",
    "plt.xlabel('residual value')\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\91915\\Desktop\\Prodigy @ T-1\\House-Price-LR.ipynb Cell 89\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/91915/Desktop/Prodigy%20%40%20T-1/House-Price-LR.ipynb#Y154sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sns\u001b[39m.\u001b[39mscatterplot(x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredicted\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresidual\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mresults)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91915/Desktop/Prodigy%20%40%20T-1/House-Price-LR.ipynb#Y154sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39maxhline(\u001b[39m0\u001b[39m, c\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91915/Desktop/Prodigy%20%40%20T-1/House-Price-LR.ipynb#Y154sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mScatterplot of residuals over predicted values\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(x='predicted', y='residual', data=results)\n",
    "plt.axhline(0, c='red')\n",
    "plt.title('Scatterplot of residuals over predicted values')\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('residual value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test['PoolQC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoolQC : data description says NA means no pool\n",
    "df_test.loc[:, \"PoolQC\"] = df_test.loc[:, \"PoolQC\"].fillna(\"None\")\n",
    "# MiscFeature : NA most likely means no noteworthy feature\n",
    "df_test.loc[:, \"MiscFeature\"] = df_test.loc[:, \"MiscFeature\"].fillna(\"None\")\n",
    "# Alley : NA most likely means no Alley\n",
    "df_test.loc[:, \"Alley\"] = df_test.loc[:, \"Alley\"].fillna(\"None\")\n",
    "# No fence\n",
    "df_test.loc[:, \"Fence\"] = df_test.loc[:, \"Fence\"].fillna(\"None\")\n",
    "# No veneer on masonry\n",
    "df_test.loc[:, \"MasVnrType\"] = df_test.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "# No fire place\n",
    "df_test.loc[:, \"FireplaceQu\"] = df_test.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "# No frontage ft or m\n",
    "df_test.loc[:, \"LotFrontage\"] = df_test.loc[:, \"LotFrontage\"].fillna(0)\n",
    "# GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "df_test.loc[:, \"GarageType\"] = df_test.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "df_test.loc[:, \"GarageFinish\"] = df_test.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "df_test.loc[:, \"GarageQual\"] = df_test.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "df_test.loc[:, \"GarageCond\"] = df_test.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "df_test.loc[:, \"GarageArea\"] = df_test.loc[:, \"GarageArea\"].fillna(0)\n",
    "df_test.loc[:, \"GarageCars\"] = df_test.loc[:, \"GarageCars\"].fillna(0)\n",
    "df_test.loc[:, \"GarageYrBlt\"] = df_test.loc[:, \"GarageYrBlt\"].fillna(0)\n",
    "\n",
    "# BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "df_test.loc[:, \"BsmtQual\"] = df_test.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "df_test.loc[:, \"BsmtCond\"] = df_test.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "df_test.loc[:, \"BsmtExposure\"] = df_test.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "df_test.loc[:, \"BsmtFinType1\"] = df_test.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "df_test.loc[:, \"BsmtFinType2\"] = df_test.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "# No veneer area\n",
    "df_test.loc[:, \"MasVnrArea\"] = df_test.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "#misc feature value\n",
    "df_test.loc[:, \"MiscVal\"] = df_test.loc[:, \"MiscVal\"].fillna(0)\n",
    "#kitchen quality\n",
    "df_test.loc[:, 'KitchenQual'] = df_test.loc[:, 'KitchenQual'].fillna(\"Fa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['PoolQC_B'] = np.where(df_test['PoolQC']=='None', 0, 1)\n",
    "\n",
    "df_test['MiscFeature_B'] = np.where(df_test['MiscFeature']=='None', 0, 1)\n",
    "\n",
    "df_test['Alley_B'] = np.where(df_test['Alley']=='None', 0, 1)\n",
    "\n",
    "df_test['Fence_B'] = np.where(df_test['Fence']=='None', 0, 1)\n",
    "\n",
    "df_test['MasVnrType_B'] = np.where(df_test['MasVnrType']=='None', 0, 1)\n",
    "\n",
    "df_test['GarageQual_B'] = np.where(df_test['MasVnrType']=='No', 0, 1)\n",
    "\n",
    "df_test['BsmtQual_B'] = np.where(df_test['MasVnrType']=='No', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.replace({\"MSZoning\" : {\"FV\" : 4, \"RL\" : 3, 'RH': 2, 'RM':2, 'C(all)':1},\n",
    "                       \"LotConfig\" : {\"CulDSac\" : 1, \"FR3\" : 1, \"FR2\" : 2, \"Corner\" : 2, \"Inside\" : 2},\n",
    "                       \"Neighborhood\" : {\"NridgHt\" : 3, \"NoRidge\" : 3, \"StoneBr\": 3, \"Timber\" : 2,  \"Somerst\" : 2, \"Veenker\": 2, \"Crawfor\" : 2, \"ClearCr\" : 2, \"CollgCr\": 2, \n",
    "                                         \"Blmngtn\" : 2, \"NWAmes\" : 2, \"Gilbert\": 2, \"SawyerW\" : 2, \"Mitchel\" : 1, \"NPkVill\": 1, \n",
    "                                         \"NAmes\" : 1, \"SWISU\" : 1, \"Blueste\": 1, \"Sawyer\" : 1, \"BrkSide\" : 1, \"Edwards\": 1, \"OldTown\" : 1,\n",
    "                                         \"BrDale\" : 1, \"IDOTRR\": 1, \"MeadowV\" : 1},\n",
    "                       \"Condition2\" : {\"PosA\" : 3, \"PosN\" : 3, \"RRAe\": 2, \"Norm\" : 2, \"RRAn\" : 1, \n",
    "                                         \"Feedr\" : 1, \"Artery\" : 1, \"RRNn\" : 1},\n",
    "                       \"BsmtFinType2\" : {\"Unf\" : 2, \"LwQ\": 2, \"Rec\" : 1, \"BLQ\" : 1, \n",
    "                                         \"ALQ\" : 2, \"GLQ\" : 3},\n",
    "                       \"BldgType\" : {\"TwnhsE\" : 2, \"1Fam\" : 2, \"Twnhs\" : 1, \"Duplex\": 1, \"2fmCon\" : 1},\n",
    "                       \"Foundation\" : {\"PConc\" : 3, \"Wood\" : 2, \"CBlock\": 2, \"Stone\": 2, \"BrkTil\": 2, \"Slab\" : 1},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 2, \"Gd\": 2, \"Ex\" : 3},\n",
    "                       \"SaleType\" : {\"Con\" : 0, \"New\" : 1, \"CWD\" : 2, \"WD\": 3, \"ConLw\" : 4, \"ConLD\" : 5 ,\n",
    "                                     \"ConLI\": 3, \"COD\" : 4, \"Oth\" : 5},\n",
    "                       \"SaleCondition\" : {\"Partial\" : 1, \"Normal\" : 2, \"Alloca\": 3, \"Family\": 4, \"Abnorml\" : 5 , \"AdjLand\" : 5},\n",
    "                       \"CentralAir\" : {\"Y\" : 2, \"N\" : 1},\n",
    "                       \"FireplaceQu\" : {\"No\" : 1,\"Po\" : 1, \"Fa\" : 1, \"TA\" : 1, \"Gd\" : 1, \"Ex\" : 2},\n",
    "                       \"MasVnrType\" : {\"Stone\" : 3, \"BrkFace\" : 2, \"BrkCmn\" : 1, \"None\" : 1},\n",
    "                       \"MiscFeature\" : {\"TenC\" : 3, \"Gar2\" : 2, \"None\" : 2, \"Shed\" : 2, \"Othr\": 1},\n",
    "                       \"Electrical\" : {\"SBrkr\" : 1, \"FuseA\" : 2, \"FuseF\" : 3, \"FuseP\" : 4, \"Mix\": 5}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.replace({\"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"OverallScore\"] = df_test[\"OverallQual\"] * df_test[\"OverallCond\"]\n",
    "\n",
    "df_test[\"ExterScore\"] = df_test[\"ExterQual\"] * df_test[\"ExterCond\"]\n",
    "\n",
    "df_test[\"BsmtScore\"] = df_test[\"BsmtQual\"] * df_test[\"BsmtCond\"]\n",
    "\n",
    "df_test[\"FlrSF\"] = df_test[\"1stFlrSF\"] + df_test[\"2ndFlrSF\"]\n",
    "\n",
    "df_test[\"GarageScore\"] = df_test[\"GarageQual\"] * df_test[\"GarageCond\"]\n",
    "\n",
    "df_test[\"LivSF\"] = df_test[\"GrLivArea\"] + df_test[\"TotalBsmtSF\"]\n",
    "\n",
    "df_test[\"Exteroverall\"] = df_test[\"ExterQual\"] * df_test[\"OverallCond\"]\n",
    "\n",
    "df_test[\"AddedScore\"] = df_test[\"BsmtQual\"] * df_test[\"GarageQual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning continuous variables into buckets based on quantiles\n",
    "df_test['AgeBldg'] = pd.qcut(df_test['YearBuilt'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Ancient', 'Vintage', 'Old', 'Average', 'New'])\n",
    "\n",
    "df_test['LastRemod']= 2010 - df_test['YearRemodAdd']\n",
    "\n",
    "df_test['StateRemod'] = pd.qcut(df_test['LastRemod'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Critical', 'Due', 'Partial', 'Optimal', 'Newly Remod'])\n",
    "\n",
    "df_test['LotFrontageRn'] = pd.qcut(df_test['LotFrontage'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Little', 'Fair', 'Adequate', 'Good', 'Excellent'])\n",
    "\n",
    "df_test['LotAreaRn'] = pd.qcut(df_test['LotArea'], q=[0, .2, .4, .6, .8, 1], \n",
    "                             labels=['Little', 'Fair', 'Adequate', 'Good', 'Excellent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['MasVnrCov']= pd.cut(df_test['MasVnrArea'], bins=[-1, 400, 800, 1200, 1601], \n",
    "                             labels=['Small', 'Sizeable', 'Optimal', 'Excellent'])\n",
    "\n",
    "df_test['MiscValRn'] = pd.cut(df_test['MiscVal'], bins=[-1, 100, 1000, 5000, 15501], \n",
    "                             labels=['Not Valuable', 'Fair', 'Good', 'Great'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = df_test.select_dtypes(exclude=np.number).columns\n",
    "num_var = df_test.select_dtypes(include=np.number).columns\n",
    "\n",
    "df_num=df_test[num_var]\n",
    "df_cat=df_test[cat_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge3 = ['LivSF', 'OverallQual', 'FlrSF', 'Neighborhood',\n",
    "       'GrLivArea', 'AddedScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2_cat= df_cat[purge2]\n",
    "df2_num= df_num[purge3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = df2_num.skew(axis=0)\n",
    "skewness = skewness[abs(skewness) > 0.5 ]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "df2_num[skewed_features] = np.log1p(df2_num[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df2_cat, df2_num], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[['LivSF']] = df_full[['LivSF']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly1=  poly.transForm(X_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SalePrice = grid_search.best_estimator_.predict(X_poly1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SalePrice = np.expm1(SalePrice)\n",
    "SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': df_test['Id'], 'SalePrice': SalePrice})\n",
    "\n",
    "# If the 'Id' column is your index, you can reset it as follows:\n",
    "submission.reset_index(drop=True, inplace=True)\n",
    "submission.to_csv('sample_submission.csv',index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
